{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzEKuROcm5SP"
   },
   "source": [
    "# **Важно!**\n",
    "\n",
    "Домашнее задание состоит из нескольких задач, которые вам нужно решить.\n",
    "*   Баллы выставляются по принципу выполнено/невыполнено.\n",
    "*   За каждую выполненую задачу вы получаете баллы (количество баллов за задание указано в скобках).\n",
    "\n",
    "**Инструкция выполнения:** Выполните задания в этом же ноутбуке (места под решения **КАЖДОЙ** задачи обозначены как **#НАЧАЛО ВАШЕГО РЕШЕНИЯ** и **#КОНЕЦ ВАШЕГО РЕШЕНИЯ**)\n",
    "\n",
    "**Как отправить задание на проверку:** Вам необходимо сохранить ваше решение в данном блокноте и отправить итоговый **файл .IPYNB** на учебной платформе в **стандартную форму сдачи домашнего задания.**\n",
    "\n",
    "**Срок проверки преподавателем:** домашнее задание проверяется **в течение 3 дней после дедлайна сдачи** с предоставлением обратной связи\n",
    "\n",
    "# **Прежде чем проверять задания:**\n",
    "\n",
    "1. Перезапустите **ядро (restart the kernel)**: в меню, выбрать **Ядро (Kernel)**\n",
    "→ **Перезапустить (Restart)**\n",
    "2. Затем **Выполнить** **все ячейки (run all cells)**: в меню, выбрать **Ячейка (Cell)**\n",
    "→ **Запустить все (Run All)**.\n",
    "\n",
    "После ячеек с заданием следуют ячейки с проверкой **с помощью assert.**\n",
    "\n",
    "Если в коде есть ошибки, assert выведет уведомление об ошибке.\n",
    "\n",
    "Если в коде нет ошибок, assert отработает без вывода дополнительной информации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvjzKaM9m5ST"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I15VyW-1m5ST"
   },
   "source": [
    "# Домашнее задание №4. Линейная классификация. Логистическая регрессия. Метод опорных векторов.\n",
    "\n",
    "**Цели домашнего задания:** Решить проблемы бинарной классификации вручную. Решить многоклассовую классификацию на примере датасета рукописных цифр MNIST с помощью готовых библиотек. Реализовать метод опорных векторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "GMC4cNE2m5SU",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c9ae45022783898a2aea57e451b47eb",
     "grade": false,
     "grade_id": "cell-d9e9033e8e7687c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Запустите эту ячейку для первоначальной настройки\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rc('lines', linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "6bg9-fuim5SV",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9aa8fc14a3b822858f8162d40474eaac",
     "grade": false,
     "grade_id": "cell-cbe327c5d8b4bfb1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Часть 1. Реализация алгоритма линейной классификации для бинарных данных\n",
    "\n",
    "В этой части, мы создадим синтетический набор бинарных данных и обучим модель вручную. Для этого нам неодходимо написать функцию сигмоиды, вычислить функцию потерь и её производную, чтобы использовать их во время градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G25H-QgTSFJ4"
   },
   "source": [
    "**Задание 1 (1 балл)**\n",
    "\n",
    "Реализуйте функцию сигмоиды `sigmoid(z)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJT9GfQ8SD2d"
   },
   "outputs": [],
   "source": [
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smoL8PTgjyKq"
   },
   "outputs": [],
   "source": [
    "assert np.isclose(sigmoid(5), 1, atol=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5oFH0MhKkasJ"
   },
   "source": [
    "**Задание 2 (1 балл)**\n",
    "\n",
    "Реализуйте логистическую функцию потерь `compute_cost(y, y_pred)`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaYP4OliknMy"
   },
   "outputs": [],
   "source": [
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "def compute_cost(y, y_pred):\n",
    "    return -np.sum(y*np.log(y_pred)+(1-y)*np.log(1-y_pred))/np.size(y)\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PikqHrBBjJH1"
   },
   "outputs": [],
   "source": [
    "y_pred = np.array([0.1, 0.8, 0.4])\n",
    "y = np.array([0, 1, 0])\n",
    "\n",
    "assert np.isclose(compute_cost(y, y_pred), 0.28, atol=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Es3WCeiBlv9c"
   },
   "source": [
    "**Задание 3 (1 балл)**\n",
    "\n",
    "Реализуйте градиент логистической функции потерь `compute_gradient(X, y, w)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wp4JDp5GpOyi"
   },
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w):\n",
    "    # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "    gradient = X.T@(sigmoid(weights@X.T)-y.T).T/X.shape[0]\n",
    "    # КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "    return gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0jpwBVjepofV"
   },
   "outputs": [],
   "source": [
    "X = np.array([[1, 2], [1, 3], [1, 4]])  # Пример данных с добавленным bias term\n",
    "y = np.array([0, 1, 0])  # Метки классов\n",
    "weights = np.array([0.1, -0.2])  # Начальные веса\n",
    "\n",
    "assert np.allclose(compute_gradient(X, y, weights), [0.04, 0.10], atol=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kxhZ7XTkpMj"
   },
   "source": [
    "**Задание 4 (1 балл)**\n",
    "\n",
    "По аналогии с предыдущим домашним заданием, реализуйте функцию градиентного спуска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "STOYOXEz6hwy"
   },
   "outputs": [],
   "source": [
    "# Функция градиентного спуска\n",
    "def gradient_descent(X, y, w, learning_rate, num_iterations):\n",
    "    # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "    for i in range(num_iterations):\n",
    "        grad = compute_gradient(X, y, w)\n",
    "        w -= learning_rate*grad/y.shape[0] \n",
    "    # КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "    return w\n",
    "gradient_descent(X, y, weights, 0.03, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "88kqK3_qlMKJ",
    "outputId": "6f6ced7f-14b8-4125-ee5b-e276943f883a"
   },
   "outputs": [],
   "source": [
    "assert np.allclose(gradient_descent(X, y, weights, 0.03, 300), [-0.01, -0.22], atol=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUDp-KAk7F0E"
   },
   "source": [
    "**Задание 5 (1 балл)**\n",
    "\n",
    "Подготовьте синтетические бинарные данные с помощью команды из библиотеки `sklearn`. Используйте функцию `make_classification`. Создайте 200 точек с двумя признаками и двумя классами, без излишних признаков (`n_redundant=0`). Зафиксируйте `random_state=42`. Добавьте столбец единиц к данным для свободного члена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GXZ4aege77Yo"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "X, y = make_classification(200, n_features=2, n_classes=2, n_redundant=0, random_state=42)\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Визуализация данных\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], color='blue', label='Класс 0', alpha=0.7)\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], color='red', label='Класс 1', alpha=0.7)\n",
    "plt.title(\"Синтетические бинарные данные\")\n",
    "plt.xlabel(\"Признак 1\")\n",
    "plt.ylabel(\"Признак 2\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9elAF0IJxoKa"
   },
   "source": [
    "**Задание 6 (1 балл)**\n",
    "\n",
    "Создайте новую переменную `X_ones`, добавив столбец единиц к данным для свободного члена с помощью `numpy` команды `concatenate`. Разбейте данные на тренировочную и тестовую выборки, выделив 20% данных под тестирование. Инициализируйте веса `weights` случайным образом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GRhM9kJISB64"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Не удаляйте и не меняйте seed\n",
    "np.random.seed(21)\n",
    "\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "X_ones = np.vstack((np.ones(200), X.T)).T\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ones, y, test_size=0.2)\n",
    "weights = np.random.rand(3)\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xGerQDd-e2k"
   },
   "outputs": [],
   "source": [
    "assert X_ones.shape[1]==3 and X_ones.shape[0]==200\n",
    "assert weights.shape[0]==3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S89lM8R4_cyZ"
   },
   "source": [
    "**Задание 7 (1 балл)**\n",
    "\n",
    "Обучите модель и предскажите значения для тестовой выборки. Вычислите значение функции потерь для тестовой выборки, `test_cost`.\n",
    "\n",
    "*Hint!* Не забудьте сигмоиду ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QxyONJqO_bCk",
    "outputId": "ce8eea82-faf4-4b80-c11d-7bad99500a3b"
   },
   "outputs": [],
   "source": [
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "w_pred = gradient_descent(X_train, y_train, weights, 0.5, 10000)\n",
    "y_pred = sigmoid(w_pred@X_test.T)\n",
    "test_cost = compute_cost(y_test, y_pred)\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2gOUhtCHCfdG"
   },
   "outputs": [],
   "source": [
    "assert np.isclose(test_cost, 0.3, atol=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GuwTkXREvj0"
   },
   "source": [
    "## Часть 2. Реализация алгоритма бинарной классификации sklearn. Сравнение результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIbR7L-NFbjS"
   },
   "source": [
    "**Задание 8 (1 балл)**\n",
    "\n",
    "Реализуйте обучение на тех же данных с помощью готовой функции `LogisticRegression` из `sklearn.linear_model`. Предскажите вероятности для тестовой выборки с помощью метода `predict_proba` и оцените качество обучения при помощи `log_loss` из `sklearn.metrics`. Запишите значение функции потерь в переменную `cost_sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yxAt028LEv4F"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict_proba(X_test)\n",
    "cost_sklearn = log_loss(y_test, y_pred)\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpuBZ9I6Gh5C"
   },
   "outputs": [],
   "source": [
    "assert np.isclose(cost_sklearn, 0.3, atol=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qiLd8iMGp7y"
   },
   "source": [
    "Обратите внимание, что мы получили схожие значения функций потерь обоими методами.\n",
    "Теперь мы можем перейти к многоклассовой классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3K8qktCJuMB5"
   },
   "source": [
    "## Часть 3. Реализация алгоритма многоклассовой классификации на примере данных `digits`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2_025qTv4kZ"
   },
   "source": [
    "Теперь, когда мы разобрались с тем, как работает обучение модели бинарной классификации, мы можем перейти к проблеме многих классов. В качестве примера, рассмотрим задачу классификации рукописных цифр из классического набора данных `digits`. Первым шагом необходимо загрузить данные. Мы будем использовать функцию `load_digits` из модуля `sklearn.datasets`, которая загрузит набор данных `digits` с цифрами от 0 до 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2cldPSWPm5SV",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3329526413375c3a5ce82d7a8badf554",
     "grade": false,
     "grade_id": "cell-dc48db25ce0a4632",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = load_digits()\n",
    "X = digits.data # изображения, преобразованные из матрицы (8, 8) в вектор (64,)\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "zpWahM82m5SV",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1815bf5d77a55487e5dc78b157621c6",
     "grade": false,
     "grade_id": "cell-c2e5221eda286ef9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Для визуализации цифр из набора данных, загруженного с помощью библиотеки scikit-learn, можно использовать функцию `imshow() `библиотеки Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "deletable": false,
    "editable": false,
    "id": "oF6tYNyLm5SW",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68d6357f48473319a0b66b00bd3d0204",
     "grade": false,
     "grade_id": "cell-e9aa8c506f284875",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "781f6e2f-e3a1-4d2b-da10-f3041945af81"
   },
   "outputs": [],
   "source": [
    "# Визуализация нескольких случайных изображений цифр\n",
    "indices = np.random.choice(len(X), 10, replace=False)\n",
    "random_digits = X[indices]\n",
    "\n",
    "# Создаём сетку 5x2 для отображения изображений\n",
    "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(10, 6))\n",
    "\n",
    "# Строим картинки в каждой ячейке сетки\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(random_digits[i].reshape((8,8)), cmap='gray')\n",
    "    ax.axis('off')  # Убираем оси\n",
    "\n",
    "# Эта команда помогает избегать наложений объектов графика\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5i8hCYecm5SW",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "892b14072309db9fdc13ffc24d4b60dd",
     "grade": false,
     "grade_id": "cell-72972e0fb60029b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Как обычно, необходимо разделить данные на обучающую и тестовую выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Z_NidS4Im5SW",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e47fee4b5879a5bb7708cb6a783f99cf",
     "grade": false,
     "grade_id": "cell-7f82013d663dd86f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "4tF3iC9Tm5SX",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f60fe43b5949f3b67658703cbd02f95",
     "grade": false,
     "grade_id": "cell-96d54fd4782001f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Задание 9 (1 балл)**\n",
    "\n",
    "Создайте по экземпляру класса `LogisticRegression` (`sklearn.linear_model`) и `SVC` (`sklearn.svm`). Внимательно почитайте официальную [документацию OneVsRestClassifier](https://scikit-learn.org/1.5/modules/generated/sklearn.multiclass.OneVsRestClassifier.html), обратите внимание на то, какие аргументы принимает этот класс. Назовите их `softmax_model` и `ovr_model`, соответственно. Обучите обе модели на данных MNIST. Сделайте предсказания для тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "iu-8KGpwm5SX",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea4f096280b3f8ecbcb99817022b06ab",
     "grade": false,
     "grade_id": "cell-6773ed1eb8bcf30c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "np.random.seed(21)\n",
    "\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "softmax_model = LogisticRegression(max_iter=1000)\n",
    "svm_model = SVC(max_iter=1000)\n",
    "softmax_model.fit(X_train, y_train)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_softmax = softmax_model.predict(X_test)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "oVvEOT6om5SX",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d75dcf60bfd26b40301ea2cce4c33c7",
     "grade": true,
     "grade_id": "cell-920798c03be6c966",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(softmax_model) == LogisticRegression and softmax_model.max_iter == 1000\n",
    "assert type(svm_model) == SVC and svm_model.max_iter == 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "dlemY_jxm5SX",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d12ea9ff32d5d2c9faf0b3ee62cf1b6",
     "grade": false,
     "grade_id": "cell-1eea5bfe58e8bd90",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Задание 10 (1 балл)**\n",
    "\n",
    "Вычислите и сравните основные метрики классификации. Для вычисления `precision`, `recall` и `F1-score` воспользуйтесь готовыми метриками из библиотки `sklearn.metrics` (найдите названия нужных функций самостоятельно). Укажите аргумент `average='macro'` для вычисления метрик усреднённых по категориям. Сохраните значения метрик в переменные:\n",
    "\n",
    "* `softmax_accuracy_score`\n",
    "* `softmax_precision_score`\n",
    "* `softmax_recall_score`\n",
    "* `softmax_f1_score`\n",
    "\n",
    "\n",
    "* `svm_accuracy_score`\n",
    "* `svm_precision_score`\n",
    "* `svm_recall_score`\n",
    "* `svm_f1_score`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "12Qe16XFm5SY",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0619735849ec0626bd2f861da88052d",
     "grade": false,
     "grade_id": "cell-caefb1f3ef2e2ebd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "import sklearn\n",
    "softmax_accuracy_score = accuracy_score(y_test, y_pred_softmax)\n",
    "\n",
    "softmax_precision_score = sklearn.metrics.precision_score(y_test, y_pred_softmax, average='macro')\n",
    "\n",
    "softmax_recall_score = sklearn.metrics.recall_score(y_test, y_pred_softmax, average='macro')\n",
    "\n",
    "softmax_f1_score = sklearn.metrics.f1_score(y_test, y_pred_softmax, average='macro')\n",
    "\n",
    "svm_accuracy_score = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "svm_precision_score = sklearn.metrics.precision_score(y_test, y_pred_svm, average='macro')\n",
    "\n",
    "svm_recall_score = sklearn.metrics.recall_score(y_test, y_pred_svm, average='macro')\n",
    "\n",
    "svm_f1_score = sklearn.metrics.f1_score(y_test, y_pred_svm, average='macro')\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5IaqiyHTlPV",
    "outputId": "498aeb69-7223-4de8-f63f-d5deb981b245"
   },
   "outputs": [],
   "source": [
    "# Качество по всем метрикам должно быть выше 95%\n",
    "print(f\"softmax_accuracy_score: {softmax_accuracy_score}\")\n",
    "print(f\"softmax_precision_score: {softmax_precision_score}\")\n",
    "print(f\"softmax_recall_score: {softmax_recall_score}\")\n",
    "print(f\"softmax_f1_score: {softmax_f1_score}\")\n",
    "\n",
    "print(f\"svm_accuracy_score: {svm_accuracy_score}\")\n",
    "print(f\"svm_precision_score: {svm_precision_score}\")\n",
    "print(f\"svm_recall_score: {svm_recall_score}\")\n",
    "print(f\"svm_f1_score: {svm_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y-iGCxHmTm3J"
   },
   "outputs": [],
   "source": [
    "assert softmax_accuracy_score > 0.95\n",
    "assert softmax_precision_score > 0.95\n",
    "assert softmax_recall_score > 0.95\n",
    "assert softmax_f1_score > 0.95\n",
    "\n",
    "assert svm_accuracy_score > 0.95\n",
    "assert svm_precision_score > 0.95\n",
    "assert svm_recall_score > 0.95\n",
    "assert svm_f1_score > 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQgXk7ZSTsPH"
   },
   "source": [
    "# Поздравляем!\n",
    "В этом домашнем задании вы вручную реализовали алгоритм логистической регрессии с помощью градиентного спуска. Вы углубили навыки пользования библиотекой `sklearn` для обучения моделей, создания синтетических данных и вычисления метрик оценки качества моделей."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
